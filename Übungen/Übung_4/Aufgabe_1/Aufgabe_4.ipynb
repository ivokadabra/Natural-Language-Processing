{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9282d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most likely word after war is ,\n",
      "The proplexity of the text  is:2.8000585347842475\n",
      "The proplexity of the text  is:1.4451579231082134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "def sentenceProplexity(data_sen,bigramProb):\n",
    "    \n",
    "    text_Proplexity=0\n",
    "    array_sentences=[]\n",
    "    sentences=[]\n",
    "    max_sentence=[]\n",
    "    n=0\n",
    "    outputProb1 = 1\n",
    "    bilist=[]\n",
    "    for k in range(len(data_sen)):  \n",
    "    \n",
    "        splt=data_sen[k]\n",
    "        N=len(data_sen)\n",
    "            \n",
    "        for i in range(len(splt) - 1):\n",
    "            if(i < len(splt) - 1):\n",
    "\n",
    "                 bilist.append((splt[i], splt[i + 1]))\n",
    "     \n",
    "        for j in bilist:\n",
    "            \n",
    "            if j in bigramProb:\n",
    "                 outputProb1 *= bigramProb[j]\n",
    "            else:\n",
    "\n",
    "                outputProb1 *= 1 \n",
    "      \n",
    "        #outputProb1=round(outputProb1,3)\n",
    "        outputProb1=pow(1/outputProb1,1/N)\n",
    "        #print(\"The proplexity of sentence\"+\" is:\"+str(outputProb1))\n",
    "        text_Proplexity+=outputProb1\n",
    "    \n",
    "    \n",
    "    print(\"The proplexity of the text \"+\" is:\"+str(text_Proplexity))\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def ersetzen(data,listOfUnigrams):\n",
    "    for i in data:\n",
    "            for j in i:\n",
    "                if j not in listOfUnigrams:\n",
    "                    number=i.index(j)\n",
    "                    i[number]=\"<UNK>\"\n",
    "    \n",
    "    return data \n",
    "\n",
    "\n",
    "def fortsetzung(word,bigramCounts,listOfBigrams,listOfUnigrams):\n",
    "    \n",
    "    probe=[]\n",
    "    \n",
    "    for bigram in listOfUnigrams:\n",
    "        if (word,bigram) in bigramCounts:\n",
    "           # if bigramCounts[(word,bigram)] > maxBigram\n",
    "           probe.append((word,bigram,bigramCounts[(word,bigram)]))\n",
    "    \n",
    "    #print(probe[0][0])\n",
    "    \n",
    "    maximum=[0,0,0]\n",
    "    for i in range(len(probe)):\n",
    "        if probe[i][2] > maximum[2]:\n",
    "            maximum=probe[i]\n",
    "    \n",
    "    print(\"The most likely word after \"+word+\" is \"+str(maximum[1]))\n",
    "    \n",
    "    #max_value = max(probe[2])\n",
    "\n",
    "    \n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def calcProbability(listOfBigrams, unigramCounts, bigramCounts,operator):\n",
    "    \n",
    "    listOfProb = {}\n",
    "    V=len(unigramCounts)\n",
    "    \n",
    "    for bigram in listOfBigrams:\n",
    "        word1 = bigram[0]\n",
    "        word2 = bigram[1]\n",
    "        if(operator==False):\n",
    "             listOfProb[bigram] = (bigramCounts.get(bigram))/(unigramCounts.get(word1))\n",
    "        else:\n",
    "             listOfProb[bigram] = (bigramCounts.get(bigram))+1/(unigramCounts.get(word1)+V)\n",
    "    \n",
    "    return listOfProb\n",
    "\n",
    "\n",
    "def calcProbabilitytrigram(listOfTrigrams, unigramCounts, trigramsCount,operator):\n",
    "    \n",
    "    listOfProb = {}\n",
    "    V=len(unigramCounts)\n",
    "    for trigram in listOfTrigrams:\n",
    "        word1 = trigram[0]\n",
    "        word2 = trigram[1]\n",
    "        word3 = trigram[2]\n",
    "        if(operator==False):\n",
    "             listOfProb[trigram] = (trigramsCount.get(trigram))/(unigramCounts.get(word1))\n",
    "        \n",
    "        else:\n",
    "             listOfProb[trigram] = (trigramsCount.get(trigram))+1/(unigramCounts.get(word1)+V)\n",
    "    \n",
    "    return listOfProb\n",
    "\n",
    "\n",
    "\n",
    "def createBigram(data):\n",
    "    listOfBigrams = []\n",
    "    bigramCounts = {}\n",
    "    listOfUnigrams = []\n",
    "    unigramCounts = {}\n",
    "    listOfTrigrams=[]\n",
    "    trigramsCount={}\n",
    "    \n",
    "    for i in range(len(data)-1):\n",
    "        if i< len(data)-1:\n",
    "                listOfBigrams.append((data[i],data[i+1]))\n",
    "                \n",
    "                if data[i] not in listOfUnigrams or i==0:\n",
    "                    listOfUnigrams.append(data[i])\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                if (data[i],data[i+1]) in bigramCounts:\n",
    "                        bigramCounts[(data[i],data[i+1])]+=1;\n",
    "                        \n",
    "                else:\n",
    "                    bigramCounts[(data[i],data[i+1])]=1;\n",
    "                    \n",
    "               \n",
    "                \n",
    "        if i< len(data)-2:\n",
    "            \n",
    "                listOfTrigrams.append((data[i],data[i+1],data[i+2]))\n",
    "                \n",
    "                if (data[i],data[i+1],data[i+2]) in trigramsCount:\n",
    "                        trigramsCount[(data[i],data[i+1],data[i+2])]+=1;\n",
    "                        \n",
    "                else:\n",
    "                    trigramsCount[(data[i],data[i+1],data[i+2])]=1;\n",
    "                    \n",
    "        if data[i] in unigramCounts:\n",
    "             unigramCounts[data[i]] += 1\n",
    "        else:\n",
    "            unigramCounts[data[i]] = 1          \n",
    "                    \n",
    "    return listOfUnigrams, listOfBigrams , bigramCounts ,unigramCounts,listOfTrigrams,trigramsCount\n",
    "\n",
    "\n",
    "\n",
    "def tokens(sentence,counter,token_sentences,tokens_for_bigrams):\n",
    "    p=token_sentences\n",
    "    if (\"<s>\" not in p[counter]):\n",
    "        p[counter].append(\"<s>\")\n",
    "        tokens_for_bigrams.append(\"<s>\")\n",
    "    \n",
    "    for x in nltk.word_tokenize(sentence):\n",
    "\n",
    "        p[counter].append(x.lower())\n",
    "        tokens_for_bigrams.append(x)\n",
    "        if (x==\".\" or x==\"?\" or x==\"!\" or x==\";\"):\n",
    "            p[counter].append(\"<\\s>\")\n",
    "            counter+=1\n",
    "            p.append([])\n",
    "            p[counter].append(\"<s>\")\n",
    "   \n",
    "    #index_1=nltk.word_tokenize(sentence).index(\".\"or\"!\")\n",
    "    #index_2=nltk.word_tokenize(sentence).index(\"!\")\n",
    "    #index_3=nltk.word_tokenize(sentence).index(\"?\")\n",
    "    #index_4=nltk.word_tokenize(sentence).index(\";\")\n",
    "    #p.append(nltk.word_tokenize(sentence))\n",
    "   \n",
    "    return p,counter,tokens_for_bigrams\n",
    "\n",
    "\n",
    "\n",
    "f = open(\"tales/HÃ¤nsel und Gretel.txt\", \"r\")\n",
    "counter=0\n",
    "token_sentences=[[]]\n",
    "tokens_for_bigrams=[]\n",
    "for x in f:\n",
    "    \n",
    "    token_sentences,counter,tokens_for_bigrams=tokens(x,counter,token_sentences,tokens_for_bigrams)\n",
    "    \n",
    "f.close()\n",
    "#print(token_sentences)\n",
    "#print(tokens_for_bigrams)\n",
    "listOfUnigrams=[]\n",
    "listOfBigrams=[] \n",
    "bigramCounts={} \n",
    "unigramCounts={} \n",
    "listOfTrigrams=[]\n",
    "trigramsCount={}\n",
    "operator=True\n",
    "listOfUnigrams, listOfBigrams , bigramCounts ,unigramCounts,listOfTrigrams,trigramsCount=createBigram(tokens_for_bigrams)\n",
    "\n",
    "bigramProb=calcProbability(listOfBigrams, unigramCounts, bigramCounts,operator=False)\n",
    "trigramProb=calcProbabilitytrigram(listOfTrigrams, unigramCounts, trigramsCount,operator=False)\n",
    "bigramProb_laplace=calcProbability(listOfBigrams, unigramCounts, bigramCounts,operator=True)\n",
    "trigramProb_laplace=calcProbabilitytrigram(listOfTrigrams, unigramCounts, trigramsCount,operator=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputList=\"<s> es war\"\n",
    "splt=inputList.split()\n",
    "word=splt[len(splt)-1]\n",
    "\n",
    "#print(bigramCounts[0])\n",
    "fortsetzung(word,bigramCounts,listOfBigrams,listOfUnigrams)\n",
    "\n",
    "text = open(\"text_1.txt\", \"r\")\n",
    "\n",
    "counter_1=0\n",
    "token_sentences_1=[[]]\n",
    "tokens_for_bigrams_1=[]\n",
    "for k in text:\n",
    "    \n",
    "    token_sentences_1,counter_1,tokens_for_bigrams_1=tokens(k,counter_1,token_sentences_1,tokens_for_bigrams_1)\n",
    "    #print(k)\n",
    "    #print(token_sentences_1)\n",
    "    \n",
    "data_1=ersetzen(token_sentences_1,listOfUnigrams)\n",
    "text.close()\n",
    "sentenceProplexity(data_1,bigramProb_laplace)\n",
    "\n",
    "\n",
    "\n",
    "text_1= open(\"text_2.txt\", \"r\")\n",
    "\n",
    "counter_2=0\n",
    "token_sentences_2=[[]]\n",
    "tokens_for_bigrams_2=[]\n",
    "for k in text_1:\n",
    "    \n",
    "    token_sentences_2,counter_2,tokens_for_bigrams_2=tokens(k,counter_2,token_sentences_2,tokens_for_bigrams_2)\n",
    "    #print(k)\n",
    "    #print(token_sentences_1)\n",
    "    \n",
    "data_2=ersetzen(token_sentences_2,listOfUnigrams)\n",
    "\n",
    "text_1.close()\n",
    "sentenceProplexity(data_2,bigramProb_laplace)\n",
    "\n",
    "\n",
    "#listOfUnigrams_1=[]\n",
    "#listOfBigrams_1=[] \n",
    "#bigramCounts_1={} \n",
    "#unigramCounts_1={} \n",
    "#listOfTrigrams_1=[]\n",
    "#trigramsCount_1={}\n",
    "\n",
    "#listOfUnigrams_1, listOfBigrams_1 , bigramCounts_1 ,unigramCounts_1,listOfTrigrams_1,trigramsCount_1=createBigram(tokens_for_bigrams)\n",
    "\n",
    "#bigramProb_1=calcProbability(listOfBigrams_1, unigramCounts_1, bigramCounts_1,operator=False)\n",
    "#trigramProb_1=calcProbabilitytrigram(listOfTrigrams_1, unigramCounts_1, trigramsCount_1,operator=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e9c36f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
