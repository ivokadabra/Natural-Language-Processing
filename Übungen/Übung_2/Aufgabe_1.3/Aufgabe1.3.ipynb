{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f9fa6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('s', '</w>'): 0}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9, (',Wha', 't'): 10}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9, (',Wha', 't'): 10, (',What', 's</w>'): 11}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9, (',Wha', 't'): 10, (',What', 's</w>'): 11, ('u', 'p'): 12}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9, (',Wha', 't'): 10, (',What', 's</w>'): 11, ('u', 'p'): 12, ('up', '</w>'): 13}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9, (',Wha', 't'): 10, (',What', 's</w>'): 11, ('u', 'p'): 12, ('up', '</w>'): 13, ('f', 'e'): 14}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9, (',Wha', 't'): 10, (',What', 's</w>'): 11, ('u', 'p'): 12, ('up', '</w>'): 13, ('f', 'e'): 14, ('fe', 'l'): 15}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9, (',Wha', 't'): 10, (',What', 's</w>'): 11, ('u', 'p'): 12, ('up', '</w>'): 13, ('f', 'e'): 14, ('fe', 'l'): 15, ('fel', 'l'): 16}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9, (',Wha', 't'): 10, (',What', 's</w>'): 11, ('u', 'p'): 12, ('up', '</w>'): 13, ('f', 'e'): 14, ('fe', 'l'): 15, ('fel', 'l'): 16, ('fell', 'a'): 17}\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9, (',Wha', 't'): 10, (',What', 's</w>'): 11, ('u', 'p'): 12, ('up', '</w>'): 13, ('f', 'e'): 14, ('fe', 'l'): 15, ('fel', 'l'): 16, ('fell', 'a'): 17, ('fella', 's</w>'): 18}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from operator import itemgetter\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from typing import Dict, Tuple, List, Set\n",
    "\n",
    "def build_vocab(corpus: str) -> dict:\n",
    "    \"\"\"Step 1. Build vocab from text corpus\"\"\"\n",
    "\n",
    "    # Separate each char in word by space and add mark end of token\n",
    "    tokens = [\" \".join(word) + \" </w>\" for word in corpus.split()]\n",
    "   \n",
    "    # Count frequency of tokens in corpus\n",
    "    vocab = Counter(tokens)  \n",
    "  \n",
    "    return vocab\n",
    "\n",
    "\n",
    "def get_stats(vocab: dict) -> dict:\n",
    "    \"\"\"Step 2. Get counts of pairs of consecutive symbols\"\"\"\n",
    "\n",
    "    pairs = defaultdict(int)\n",
    "    \n",
    "    for word, frequency in vocab.items():\n",
    "        symbols = word.split()\n",
    "       \n",
    "        for i in range(len(symbols) - 1):\n",
    "           \n",
    "            pairs[symbols[i], symbols[i + 1]] += frequency\n",
    "           \n",
    "            \n",
    "    return pairs\n",
    "\n",
    "\n",
    "def merge_vocab(pair: tuple, v_in: dict) -> dict:\n",
    "    \"\"\"Step 3. Merge all occurrences of the most frequent pair\"\"\"\n",
    "    \n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    \n",
    "    for word in v_in:\n",
    "        # replace most frequent pair in all vocabulary\n",
    "        w_out = p.sub(''.join(pair), word)\n",
    "        v_out[w_out] = v_in[word]\n",
    "\n",
    "    return v_out\n",
    "\n",
    "corpus=\"I am Ivo ,Whats up fellas\"\n",
    "test_sentence=\"Hello IVO how are you fellas\"\n",
    "\n",
    "vocab = build_vocab(corpus) # Step 1\n",
    "#print(vocab)\n",
    "\n",
    "bpe_codes = {}\n",
    "num_merges = 50  # Hyperparameter\n",
    "for i in range(num_merges):\n",
    "    #print(\"Merge Nummer\" +str(i))\n",
    "    pairs = get_stats(vocab)  # Step 2\n",
    "    #print(pairs)\n",
    "    if not pairs:\n",
    "        break\n",
    "\n",
    "    # step 3\n",
    "    best = max(pairs, key=pairs.get)\n",
    "    bpe_codes[best] = i\n",
    "    print(bpe_codes)\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    #print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b582a308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'v', 'o', 't', 'o', '</w>']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_word = 'Ivoto'\n",
    "word = list(original_word)\n",
    "word.append('</w>')\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "569924f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('I', 'v'), ('o', '</w>'), ('o', 't'), ('t', 'o'), ('v', 'o')}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pairs(word:list):\n",
    "    pairs = set()\n",
    "    prev_char = word[0]\n",
    "    for char in word[1:]:\n",
    "        pairs.add((prev_char, char))\n",
    "        prev_char = char\n",
    "\n",
    "    return pairs\n",
    "\n",
    "pairs = get_pairs(word)\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2ea75779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('I', 'v'), 4)]\n",
      "{('s', '</w>'): 0, ('I', '</w>'): 1, ('a', 'm'): 2, ('am', '</w>'): 3, ('I', 'v'): 4, ('Iv', 'o'): 5, ('Ivo', '</w>'): 6, (',', 'W'): 7, (',W', 'h'): 8, (',Wh', 'a'): 9, (',Wha', 't'): 10, (',What', 's</w>'): 11, ('u', 'p'): 12, ('up', '</w>'): 13, ('f', 'e'): 14, ('fe', 'l'): 15, ('fel', 'l'): 16, ('fell', 'a'): 17, ('fella', 's</w>'): 18}\n",
      "{('t', 'o'), ('o', 't'), ('v', 'o'), ('o', '</w>'), ('I', 'v')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('I', 'v')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = get_pairs(word)\n",
    "bpe_codes_pairs = [(pair, bpe_codes[pair]) for pair in pairs if pair in bpe_codes]\n",
    "print(bpe_codes_pairs)\n",
    "print(bpe_codes)\n",
    "print(pairs)\n",
    "pair_to_merge = min(bpe_codes_pairs, key=itemgetter(1))[0]\n",
    "pair_to_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d8faa5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iv', 'o', 't', 'o', '</w>']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_new_word(word: List[str], pair_to_merge: Tuple[str, str]):\n",
    "    first, second = pair_to_merge\n",
    "    new_word = []\n",
    "    i = 0\n",
    "    while i < len(word):\n",
    "        try:\n",
    "            j = word.index(first, i)\n",
    "            new_word.extend(word[i:j])\n",
    "            i = j\n",
    "        except ValueError:\n",
    "            new_word.extend(word[i:])\n",
    "            break\n",
    "\n",
    "        if i < len(word) - 1 and word[i + 1] == second:\n",
    "            \n",
    "            new_word.append(first + second)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_word.append(first)\n",
    "            i += 1\n",
    "\n",
    "    return new_word\n",
    "\n",
    "new_word = create_new_word(word, pair_to_merge)\n",
    "new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9e41a51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ivo', 't', 'o', '</w>']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_segmenter(original_word: str, bpe_codes: Dict[Tuple[str, str], int]):\n",
    "    if len(original_word) == 1:\n",
    "        return original_word\n",
    "\n",
    "    word = list(original_word)\n",
    "    word.append('</w>')\n",
    "\n",
    "    while True:\n",
    "        pairs = get_pairs(word)\n",
    "        bpe_codes_pairs = [(pair, bpe_codes[pair]) for pair in pairs if pair in bpe_codes]\n",
    "        if not bpe_codes_pairs:\n",
    "            break\n",
    "\n",
    "        pair_to_merge = min(bpe_codes_pairs, key=itemgetter(1))[0]\n",
    "        word = create_new_word(word, pair_to_merge)\n",
    "\n",
    "    return word\n",
    "\n",
    "original_word = 'Ivoto'\n",
    "token_segmenter(original_word, bpe_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e8dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
